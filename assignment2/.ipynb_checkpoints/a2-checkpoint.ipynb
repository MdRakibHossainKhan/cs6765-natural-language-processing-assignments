{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f036af-cc08-49bc-aba8-93bc883bd7f5",
   "metadata": {},
   "source": [
    "# CS4765/6765 Assignment 2: Sentiment Analysis\n",
    "\n",
    "**Due 9 October at 23:59**\n",
    "\n",
    "We've seen the problem of sentiment analysis in class. In this\n",
    "assignment you will write your own sentiment analysis system. You will\n",
    "implement an unsupervised lexicon-based method and two variants of a\n",
    "naive Bayes classifier. The starter code further provides a most-frequent class baseline and logistic regression. You will then compare the various\n",
    "approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d8065-f777-401c-a109-47c3e6be2b43",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "I've provided you with the following files for this assignment:\n",
    "\n",
    "- `movie_reviews_{train,dev,test}_docs.txt` Training, development, and test\n",
    "  documents, in 1 document per line format. The documents have been tokenized, with each token separated by whitespace.\n",
    "  These are movie reviews and have gold standard labels of \n",
    " `positive` or `negative`.\n",
    "\n",
    "  **These are real movie reviews. Some of the documents contain content\n",
    "    that you might find offensive (e.g., expletives, racist remarks).\n",
    "    Despite this offensive content, these movie reviews\n",
    "    are still valuable data, and building NLP systems that can\n",
    "    operate over them is important. That is why we are working with\n",
    "    this potentially-offensive data in this assignment.**\n",
    "\n",
    "  The data for this assignment is from the movie reviews dataset included as part of NLTK. You can read more about this dataset here: http://www.cs.cornell.edu/people/pabo/movie-review-data/ You should only use the files I've provided you with for this assignment.\n",
    "\n",
    "- `movie_reviews_{train,dev,test}_classes.txt` Class labels for\n",
    "  the training, development, and test data, in 1 label per line format. The labels are\n",
    "  `positive` and `negative`.\n",
    "\n",
    "- `{pos,neg}-words.txt` Lists of positive and\n",
    "  negative words, in 1 word per line format. These lists are from the \"Opinion\n",
    "  Lexicon\" provided by Bing\n",
    "  Liu (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon).\n",
    "  I've stripped the header information from the original files so that the\n",
    "  code here doesn't have to deal with that, and dealt with a minor encoding\n",
    "  issue.\n",
    "\n",
    "The starter code that I've provided below handles reading from these files for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809f82d-764b-40c7-bbb5-35cd3137c496",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "In this assignment you will implement three different approaches to sentiment analysis: a sentiment lexicon baseline, multinomial naive Bayes, and binary multinomial naive Bayes. The starter code further includes a most-frequent class baseline and logistic regression. Further details on the models are provided below.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Your code must be able to run on the NLP VM on the lab machines using Python 3.9. You must not use NLTK or any other NLP toolkits. You should not import any modules that this notebook does not already import for you. Although the starter code uses an implementation of logistic regression from scikit-learn, you must not use scikit-learn for any of the code that you write in this assignment.\n",
    "\n",
    "## Experimental Setup\n",
    "\n",
    "Throughout this assignment, we will always use the training data for training models. We will implement our models and then use the development data for preliminary evaluation. Once we've completed this, we will do our final evaluation on the test data. The starter code guides you through this process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4862fe4-b071-4873-a194-7d615ed17dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very simple tokenizer. Applies case folding. \n",
    "# (The documents we are working with have already been tokenized and each token is separated by whitespace.)\n",
    "def tokenize(s):\n",
    "    return s.lower().split()\n",
    "\n",
    "train_texts_fname = 'a2data/movie_reviews_train_docs.txt'\n",
    "train_klasses_fname = 'a2data/movie_reviews_train_classes.txt'\n",
    "dev_texts_fname = 'a2data/movie_reviews_dev_docs.txt'\n",
    "dev_klasses_fname = 'a2data/movie_reviews_dev_classes.txt'\n",
    "\n",
    "train_texts = [x.strip() for x in open(train_texts_fname, encoding='utf8')]\n",
    "train_klasses = [x.strip() for x in open(train_klasses_fname, encoding='utf8')]\n",
    "dev_texts = [x.strip() for x in open(dev_texts_fname, encoding='utf8')]\n",
    "dev_klasses = [x.strip() for x in open(dev_klasses_fname, encoding='utf8')]\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# A helper function to print out macro-average P,R,F1 and accuracy.\n",
    "# Uses implementantions of evaluation metrics from sklearn.\n",
    "def print_results(gold_labels, predicted_labels):\n",
    "    p,r,f,_ = precision_recall_fscore_support(gold_labels, \n",
    "                                              predicted_labels, \n",
    "                                              average='macro', \n",
    "                                              zero_division=0)\n",
    "    acc = accuracy_score(gold_labels, predicted_labels)\n",
    "\n",
    "    print(\"Precision: \", p)\n",
    "    print(\"Recall: \", r)\n",
    "    print(\"F1: \", f)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0990d75-fde0-4fd9-9898-a2ef022ddd23",
   "metadata": {},
   "source": [
    "## Most-frequent Class Baseline\n",
    "\n",
    "The starter code below trains a most-frequent class baseline on the training data and evaluates it on the dev data. (Note that sklearn also includes an implementation of a most-frequent class baseline, which you might find useful for your projects: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d26ab4-0413-4bef-b204-fae3449a4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A most-frequent class baseline\n",
    "class Baseline:\n",
    "    def __init__(self, klasses):\n",
    "        self.train(klasses)\n",
    "\n",
    "    def train(self, klasses):\n",
    "        # Count classes to determine which is the most frequent\n",
    "        klass_freqs = {}\n",
    "        for k in klasses:\n",
    "            klass_freqs[k] = klass_freqs.get(k, 0) + 1\n",
    "        self.mfc = sorted(klass_freqs, reverse=True, \n",
    "                          key=lambda x : klass_freqs[x])[0]\n",
    "    \n",
    "    def classify(self, test_instance):\n",
    "        # Ignore the test instance and always return the most frequent class\n",
    "        return self.mfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f09ac6-5966-437f-9957-47b6d2c06b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.24375\n",
      "Recall:  0.5\n",
      "F1:  0.3277310924369748\n",
      "Accuracy:  0.4875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_classifier = Baseline(train_klasses)\n",
    "baseline_dev_predictions = [baseline_classifier.classify(x) for x in dev_texts]\n",
    "print_results(dev_klasses, baseline_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a8388-991d-4748-a849-b3b0cb51eb0f",
   "metadata": {},
   "source": [
    "## Lexicon Baseline (1 mark)\n",
    "\n",
    "A simple baseline approach is to use a polarity lexicon (i.e., the\n",
    "lists of positive and negative words you've been provided with) to\n",
    "determine the number of positive and negative tokens in a test\n",
    "document, and then output the class label associated with the most\n",
    "tokens. In the event of a tie, select the most frequent class. \n",
    "\n",
    "Implement this approach by completing the `classify` method below.\n",
    "You should not modify any other parts of the code.\n",
    "\n",
    "Then run the provided code to train this classifier on the training data\n",
    "and evaluate on the development data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0488d66-3959-44de-9f22-2482c694b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexiconBL:\n",
    "    def __init__(self, pos_fname, neg_fname):\n",
    "        self.pos_words = set([x.strip() for x in open(pos_fname,\n",
    "                                                      encoding='utf8')])\n",
    "        self.neg_words = set([x.strip() for x in open(neg_fname,\n",
    "                                                      encoding='utf8')])\n",
    "\n",
    "    def classify(self, test_instance):\n",
    "        # Given a test_instance (a string representing a tweet), \n",
    "        # return its predicted class ('positive' or 'negative')\n",
    "\n",
    "        tokens = tokenize(test_instance)\n",
    "\n",
    "        # TODO: Complete this method\n",
    "        \n",
    "        pos_counter = 0\n",
    "        neg_counter = 0\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in self.pos_words:\n",
    "                pos_counter += 1\n",
    "            elif token in self.neg_words:\n",
    "                neg_counter += 1\n",
    "\n",
    "        if pos_counter >= neg_counter:\n",
    "            return 'positive'\n",
    "        else:\n",
    "            return 'negative'\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd4f678-67af-422d-b40d-39ddc60745ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6880442398158343\n",
      "Recall:  0.6879924953095685\n",
      "F1:  0.6874980468627929\n",
      "Accuracy:  0.6875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the lexicon baseline on the training data and evaluate on the dev data\n",
    "pos_fname = 'a2data/pos-words.txt'\n",
    "neg_fname = 'a2data/neg-words.txt'\n",
    "\n",
    "lexiconBL_classifier = LexiconBL(pos_fname, neg_fname)\n",
    "lexiconBL_dev_predictions = [lexiconBL_classifier.classify(x) for x in dev_texts]\n",
    "\n",
    "print_results(dev_klasses, lexiconBL_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da9259-32cf-4daa-8276-77df60215531",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The implementation below uses the scikit-learn (sklearn) Python module for logistic regression. Scikit-learn is a popular tool for doing many machine learning tasks in Python. It includes implementations of many classifiers (including naive Bayes, but we're implementing that ourselves in this assignment). Read the comments in the code below to learn how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9160c0f0-b063-4807-afee-1bd7a8002112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rakib\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8355222013758599\n",
      "Recall:  0.8355222013758599\n",
      "F1:  0.835\n",
      "Accuracy:  0.835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sklearn provides functionality for tokenizing text and\n",
    "# extracting features from it. This uses the tokenize function\n",
    "# defined above for tokenization (as opposed to sklearn's\n",
    "# default tokenization) so the results can be more easily\n",
    "# compared with those using NB and the sentiment lexicon\n",
    "# baseline.\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "count_vectorizer = CountVectorizer(analyzer=tokenize)\n",
    "\n",
    "# train_counts will be a DxV matrix where D is the number of\n",
    "# training documents and V is the number of types in the\n",
    "# training documents. Each cell in the matrix indicates the\n",
    "# frequency (count) of a type in a document.\n",
    "train_counts = count_vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Train a logistic regression classifier on the training\n",
    "# data. A wide range of options are available. This does\n",
    "# something similar to what we saw in class, i.e., multinomial\n",
    "# logistic regression (multi_class='multinomial') using\n",
    "# stochastic average gradient descent (solver='sag') with L2\n",
    "# regularization (penalty='l2'). The maximum number of\n",
    "# iterations is set to 2000 (max_iter=2000) to allow the model\n",
    "# to converge on this training data. The random_state is set to 0 \n",
    "# (an arbitrarily chosen number) to help ensure results are \n",
    "# consistent from run to run.\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "lr = LogisticRegression(multi_class='multinomial',\n",
    "                        solver='sag',\n",
    "                        penalty='l2',\n",
    "                        max_iter=2000,\n",
    "                        random_state=0)\n",
    "lr_classifier = lr.fit(train_counts, train_klasses)\n",
    "\n",
    "# Transform the test documents into a DxV matrix, similar to\n",
    "# that for the training documents, where D is the number of\n",
    "# test documents, and V is the number of types in the training\n",
    "# documents. Here we will test on the development data.\n",
    "dev_counts = count_vectorizer.transform(dev_texts)\n",
    "\n",
    "# Predict the class for each test document\n",
    "lr_dev_predictions = lr_classifier.predict(dev_counts)\n",
    "print_results(dev_klasses, lr_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c761b-428c-4a37-a6ba-acfe40d182de",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes (5 marks)\n",
    "\n",
    "Implement multinomial naive Bayes, i.e., as described in Chapter 4.1-4.3 of the text book. Follow the structure of the starter code provided. Read the comments in the code, and the description below, to understand how it is intended to work.\n",
    "\n",
    "- The constructor, `__init__`, should train the classifier on the provided training data. Similarly to the constructor for `Baseline` above,   you might find it useful to have the constructor call helper methods (i.e., `train` in the case of `Baseline`).\n",
    "\n",
    "- `classify` predicts the class for a provided test instance. Be sure to compute probabilities in log space to avoid underflow errors\n",
    "  from multiplying many probabilities.\n",
    "\n",
    "- **Optional:** It can be very helpful to ensure that your probability distributions are actually\n",
    "  probability distributions! You can do this by adding `assert` statements to `sanity_check` to make\n",
    "  sure that all the probabilities you estimate are between 0 and 1,\n",
    "  and that the distributions you estimate sum to 1, e.g., $\\sum_{w \\in\n",
    "  V}P(w|c) = 1$.\n",
    "\n",
    "  You can add further simple checks to your code, for example, `__init__` checks that the number of training documents and training classes are the same. (If this were not the case, then each document would not have exactly one class label, indicating a problem, perhaps that the constructor was called incorrectly.) You might want to make sure that all the classes you output are `positive` or `negative`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df96c5f5-c625-4a4e-ac8d-a8f727a9c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class NB:\n",
    "\n",
    "    # TODO: Complete this class\n",
    "\n",
    "    def __init__(self, documents,\n",
    "                 klasses,\n",
    "                 binary=False):\n",
    "        # documents is a list of training documents. You will need to tokenize each document.\n",
    "        # klasses is a list of corresponding classes for the training documents (I.e.,\n",
    "        # klasses[i] is the class for document[i]).\n",
    "        # binary indicates whether to use binary multinomial naive Bayes (which you will\n",
    "        # implement in the next step) or (regular) multinomial naive Bayes. You can ignore\n",
    "        # it when you first implement multinomial naive Bayes, and then use it to implement\n",
    "        # binary multinomial naive Bayes after.\n",
    "        assert len(documents) == len(klasses)\n",
    "        self.binary = binary\n",
    "         \n",
    "        self.vocab = set()\n",
    "        self.class_word_counts = {'positive': {}, 'negative': {}}\n",
    "        self.class_doc_counts = {'positive': 0, 'negative': 0}\n",
    "        self.class_total_words = {'positive': 0, 'negative': 0}\n",
    "        self.prior_prob = {'positive': 0, 'negative': 0}\n",
    "\n",
    "        for doc, klass in zip(documents, klasses):\n",
    "            tokens = tokenize(doc)\n",
    "            self.class_doc_counts[klass] += 1\n",
    "\n",
    "            token_set = set(tokens) if self.binary else tokens\n",
    "            for token in token_set:\n",
    "                if not self.binary or token not in self.class_word_counts[klass]:\n",
    "                    if token not in self.class_word_counts[klass]:\n",
    "                        self.class_word_counts[klass][token] = 0\n",
    "                    self.class_word_counts[klass][token] += 1\n",
    "                    self.class_total_words[klass] += 1\n",
    "                    self.vocab.add(token)\n",
    "\n",
    "        total_docs = len(documents)\n",
    "        self.prior_prob['positive'] = math.log(self.class_doc_counts['positive'] / total_docs)\n",
    "        self.prior_prob['negative'] = math.log(self.class_doc_counts['negative'] / total_docs)\n",
    "\n",
    "        self.sanity_check()\n",
    "\n",
    "    def sanity_check(self):\n",
    "        # You might want to add some checks here to check that, for example,\n",
    "        # you've estimated valid probability distributions\n",
    "        assert self.prior_prob['positive'] <= 0\n",
    "        assert self.prior_prob['negative'] <= 0\n",
    "        \n",
    "        assert len(self.vocab) > 0\n",
    "\n",
    "    def classify(self, test_instance):\n",
    "        # test_instance is an instance to classify. \n",
    "        # Return the predicted class: must be one of 'positive' or 'negative'\n",
    "        tokens = tokenize(test_instance)\n",
    "        \n",
    "        log_prob_positive = self.prior_prob['positive']\n",
    "        log_prob_negative = self.prior_prob['negative']\n",
    "\n",
    "        token_set = set(tokens) if self.binary else tokens\n",
    "        vocab_size = len(self.vocab)\n",
    "\n",
    "        for token in token_set:\n",
    "            count_positive = self.class_word_counts['positive'].get(token, 0) + 1\n",
    "            prob_word_given_positive = count_positive / (self.class_total_words['positive'] + vocab_size)\n",
    "            log_prob_positive += math.log(prob_word_given_positive)\n",
    "\n",
    "            count_negative = self.class_word_counts['negative'].get(token, 0) + 1\n",
    "            prob_word_given_negative = count_negative / (self.class_total_words['negative'] + vocab_size)\n",
    "            log_prob_negative += math.log(prob_word_given_negative)\n",
    "\n",
    "        return 'positive' if log_prob_positive > log_prob_negative else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2135002-76ab-4ba5-9f81-a9469468002c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8227806458143536\n",
      "Recall:  0.8190744215134459\n",
      "F1:  0.8171697628842096\n",
      "Accuracy:  0.8175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = NB(train_texts, train_klasses)\n",
    "nb_classifier.sanity_check()\n",
    "nb_dev_predictions = [nb_classifier.classify(x) for x in dev_texts]\n",
    "print_results(dev_klasses, nb_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5cc737-9b5f-4591-aea6-e47eff6e262c",
   "metadata": {},
   "source": [
    "## Binary Multinomial Naive Bayes (1 mark)\n",
    "\n",
    "Also implement binary multinomial naive Bayes (i.e., multinomial naive Bayes with binary features). Recall\n",
    "that in this model, the frequency of a given word in a given document\n",
    "is either 0 (if the word does not occur in the document) or 1 (if the\n",
    "word occurs 1 or more times in the document). Repeated occurrences of\n",
    "a word are ignored. This model is discussed in Chapter 4.4 of the text book.\n",
    "\n",
    "Implement this model by adding functionality to the class `NB` for when the value `True` is passed to the constructor for the parameter `binary`. **Hint** This should be a very small amount of additional code. If you're writing lots of code, you are likely off track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "727a8bb8-1ff1-4a06-896e-9ab71d5f24c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6894245185099758\n",
      "Recall:  0.5410881801125704\n",
      "F1:  0.4233836339099497\n",
      "Accuracy:  0.53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bin_nb_classifier = NB(train_texts, train_klasses, binary=True)\n",
    "bin_nb_classifier.sanity_check()\n",
    "bin_nb_dev_predictions = [bin_nb_classifier.classify(x) for x in dev_texts]\n",
    "print_results(dev_klasses, bin_nb_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09cf8c-2a15-4b52-9221-3fdf366f6882",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "\n",
    "So far, we've only evaluated on the development data. Once you have completed the tasks above (i.e., your implementations of the classes `LexiconBL` and `NB`), run the code below to evaluate the classifiers on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e422ae76-76bf-445d-9248-b9165020de44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results:\n",
      "\n",
      "Baseline:\n",
      "Precision:  0.24125\n",
      "Recall:  0.5\n",
      "F1:  0.3254637436762226\n",
      "Accuracy:  0.4825\n",
      "\n",
      "Lexicon Baseline:\n",
      "Precision:  0.7300932523313083\n",
      "Recall:  0.7303697028860354\n",
      "F1:  0.7299392363281738\n",
      "Accuracy:  0.73\n",
      "\n",
      "Logistic Regression\n",
      "Precision:  0.8634259259259259\n",
      "Recall:  0.8615428900402993\n",
      "F1:  0.8620438825868026\n",
      "Accuracy:  0.8625\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "Precision:  0.775094377359434\n",
      "Recall:  0.7754248954969838\n",
      "F1:  0.7749493636068115\n",
      "Accuracy:  0.775\n",
      "\n",
      "Binary Multinomial Naive Bayes:\n",
      "Precision:  0.7112771739130435\n",
      "Recall:  0.5622762884533553\n",
      "F1:  0.46001983905011223\n",
      "Accuracy:  0.5475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_texts_fname = 'a2data/movie_reviews_test_docs.txt'\n",
    "test_klasses_fname = 'a2data/movie_reviews_test_classes.txt'\n",
    "\n",
    "test_texts = [x.strip() for x in open(test_texts_fname, encoding='utf8')]\n",
    "test_klasses = [x.strip() for x in open(test_klasses_fname, encoding='utf8')]\n",
    "\n",
    "print(\"Test results:\")\n",
    "print()\n",
    "\n",
    "print(\"Baseline:\")\n",
    "baseline_test_predictions = [baseline_classifier.classify(x) for x in test_texts]\n",
    "print_results(test_klasses, baseline_test_predictions)\n",
    "\n",
    "print(\"Lexicon Baseline:\")\n",
    "lexiconBL_test_predictions = [lexiconBL_classifier.classify(x) for x in test_texts]\n",
    "print_results(test_klasses, lexiconBL_test_predictions)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "test_counts = count_vectorizer.transform(test_texts)\n",
    "lr_test_predictions = lr_classifier.predict(test_counts)\n",
    "print_results(test_klasses, lr_test_predictions)\n",
    "\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "nb_test_predictions = [nb_classifier.classify(x) for x in test_texts]\n",
    "print_results(test_klasses, nb_test_predictions)\n",
    "\n",
    "print(\"Binary Multinomial Naive Bayes:\")\n",
    "bin_nb_test_predictions = [bin_nb_classifier.classify(x) for x in test_texts]\n",
    "print_results(test_klasses, bin_nb_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c753c0d-b843-4c04-a572-84484b7cae73",
   "metadata": {},
   "source": [
    "## Report (3 marks)\n",
    "\n",
    "Write a brief report describing the results of the various methods for sentiment analysis considered in this assignment. Base your analysis on the results over the test data. Address at least the following in your report:\n",
    "\n",
    "1. Which of the two baseline methods (most-frequent class or sentiment lexicon) performs best?\n",
    "\n",
    "1. Do the other methods (multinomial naive Bayes, binary multinomial naive Bayes, and logistic regression) outperform the baseline methods?\n",
    "\n",
    "1. Does binary multinomial naive Bayes outperform (vanilla) multinomial naive Bayes? \n",
    "\n",
    "1. Consider binary multinomial naive Bayes and logistic regression. Which of these methods performs best? \n",
    "\n",
    "1. Carry out some error analysis to attempt to explain what causes the difference in performance between binary multinomial naive Bayes and logistic regression. For this, you might find it helpful to examine the per-class P, R, and F values, or a confusion matrix. You can do this using `sklearn.metrics.precision_recall_fscore_support` and `sklearn.metrics.confusion_matrix`. You can read the documentation for these functions here:\n",
    "  \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "   \n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "    I've also included some examples of how to use them below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411dbc0-5a06-46f0-9d52-c61218793ad1",
   "metadata": {},
   "source": [
    "**TODO: Write your report here**\n",
    "\n",
    "If you wrote code to get your answers (e.g., for the last question) also include that code in code blocks below.\n",
    "\n",
    "1. Most frequent class baseline works best when there is class imbalance, as it always predicts the majority class. However, it ignores the content of the document.\n",
    "The sentiment lexicon baseline uses word lists and usually performs better if the lexicon matches the dataset well.\n",
    "\n",
    "2. Yes, multinomial Naive Bayes, binary Naive Bayes, and logistic regression usually outperform baseline methods. They use more detailed word information (frequency or presence), leading to better predictions. Logistic regression often performs the best due to its flexibility.\n",
    "\n",
    "3. Binary multinomial Naive Bayes can outperform multinomial Naive Bayes when word presence is more important than frequency, but it depends on the dataset. For most text tasks, vanilla multinomial Naive Bayes usually performs better due to its use of word frequencies.\n",
    "\n",
    "4. Logistic regression generally performs better than binary multinomial Naive Bayes because it's more flexible and captures complex decision boundaries.\n",
    "\n",
    "5. Key Points of Error Analysis:\n",
    "\n",
    "Precision, Recall, F1-Score:\n",
    "a. Logistic regression generally has higher precision, meaning fewer false positives.\n",
    "b. Binary Naive Bayes may have higher recall, meaning it captures more true positives but may misclassify more negatives as positives.\n",
    "\n",
    "Confusion Matrix:\n",
    "a. Shows where each model makes mistakes (false positives, false negatives).\n",
    "b. Logistic regression typically has fewer misclassifications due to its ability to capture complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b418177-fe09-4bb7-821d-8b4a487f72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary Naive Bayes - Precision, Recall, F1 per class: (array([0.51630435, 0.90625   ]), array([0.98445596, 0.14009662]), array([0.67736185, 0.24267782]))\n",
      "Binary Naive Bayes - Confusion Matrix:\n",
      " [[190   3]\n",
      " [178  29]]\n",
      "\n",
      "Logistic Regression - Precision, Recall, F1 per class: (array([0.80628272, 0.81339713]), array([0.79792746, 0.82125604]), array([0.80208333, 0.81730769]))\n",
      "Logistic Regression - Confusion Matrix:\n",
      " [[154  39]\n",
      " [ 37 170]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg_pipeline = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(max_iter=1000))\n",
    "log_reg_pipeline.fit(X_train, train_klasses)\n",
    "\n",
    "# Binary Multinomial Naive Bayes predictions\n",
    "bin_nb_predictions = [bin_nb_classifier.classify(x) for x in test_texts]\n",
    "\n",
    "# Logistic Regression predictions\n",
    "log_reg_predictions = log_reg_pipeline.predict(X_test)\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(true_labels, predictions, model_name):\n",
    "    metrics = precision_recall_fscore_support(true_labels, predictions, average=None)\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "    print(f\"\\n{model_name} - Precision, Recall, F1 per class:\", metrics[:3])\n",
    "    print(f\"{model_name} - Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Evaluate both models\n",
    "evaluate_model(test_klasses, bin_nb_predictions, \"Binary Naive Bayes\")\n",
    "evaluate_model(test_klasses, log_reg_predictions, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd7499-e1d8-4a28-abc5-f6f0946bb830",
   "metadata": {},
   "source": [
    "Examples that might be useful for error analysis for question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "883625a0-c518-44e2-89b7-1dba2cf785ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.90625]),\n",
       " array([0.14009662]),\n",
       " array([0.24267782]),\n",
       " array([207], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculte P, R, F for the positive class for binary NB on the test data.\n",
    "precision_recall_fscore_support(test_klasses, bin_nb_test_predictions, labels=['positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9e0104d-c6c7-4d3d-9277-ff03f5493132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29,   3],\n",
       "       [178, 190]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute a confusion matrix for Binary NB on the test data. Note that \n",
    "# I've transposed the confusion matrix so that the rows correspond to \n",
    "# system predictions and columns correspond to gold standard labels, \n",
    "# following the convention in the textbook and class. (By default, \n",
    "# sklearn does it the other way around.)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_klasses, bin_nb_test_predictions, labels=['positive', 'negative']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee95dde-e1ad-43c2-acbe-eee1398fc258",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## What to submit\n",
    "\n",
    "When you're done, submit a2.ipynb to the assignment 2 folder on D2L by the deadline.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
